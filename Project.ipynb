{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0693203c-2f9d-42b3-a762-a69eb1bb51d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from requests) (2024.6.2)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.2\n",
      "Requirement already satisfied: pandas in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install bs4\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffabe874-3fd1-452c-99da-a108d61b6cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb2b42e-d2f9-4019-a28e-fc47039db3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ragadjalelabed\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "03d19c2a-3e5a-4d42-80a9-41cb2bcff8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more apartments found in borough REGION%5E93953.\n",
      "No more apartments found in borough REGION%5E61417.\n",
      "Total listings scraped: 2100\n",
      "Sample data:\n",
      "                                               Links  \\\n",
      "0  https://www.rightmove.co.uk/properties/1472160...   \n",
      "1  https://www.rightmove.co.uk/properties/1489738...   \n",
      "2  https://www.rightmove.co.uk/properties/1426485...   \n",
      "3  https://www.rightmove.co.uk/properties/1469238...   \n",
      "4  https://www.rightmove.co.uk/properties/1487114...   \n",
      "\n",
      "                                    Address       Price Property Type  \\\n",
      "0           Kimpton Court, Murrain Road, N4    £500,000          Flat   \n",
      "1                     Principal Place, EC2A  £9,900,000          Flat   \n",
      "2             Principal Tower, London, EC2A  £9,900,000     Penthouse   \n",
      "3  Principal Tower, 2 Principal Place, EC2A  £9,900,000          Flat   \n",
      "4               Principal Tower, Shoreditch  £9,900,000     Penthouse   \n",
      "\n",
      "            Added Date Bedrooms Bathrooms                   Size  \\\n",
      "0  Added on 24/04/2024        1         1              Ask agent   \n",
      "1  Added on 10/06/2024        2         2  2,855 sq ft, 265 sq m   \n",
      "2  Added on 04/12/2023        3         3  2,852 sq ft, 265 sq m   \n",
      "3  Added on 17/04/2024        3         4  2,855 sq ft, 265 sq m   \n",
      "4  Added on 05/07/2024        3         3  2,855 sq ft, 265 sq m   \n",
      "\n",
      "  Leasehold/Freehold Council Tax    Parking     Garden  \\\n",
      "0  TENURE\\nLeasehold   Ask agent  Ask agent  Ask agent   \n",
      "1  TENURE\\nLeasehold   Ask agent        Yes    Terrace   \n",
      "2  TENURE\\nLeasehold   Ask agent    Private    Terrace   \n",
      "3  TENURE\\nLeasehold   Ask agent        Yes  Ask agent   \n",
      "4  TENURE\\nLeasehold     Band: C        Yes  Ask agent   \n",
      "\n",
      "                                            Stations  \\\n",
      "0  Manor House Station0.6 miles, Finsbury Park St...   \n",
      "1  Shoreditch High Street Station0.2 miles, Liver...   \n",
      "2  Liverpool Street Station0.3 miles, Moorgate St...   \n",
      "3  Shoreditch High Street Station0.3 miles, Liver...   \n",
      "4  Shoreditch High Street Station0.2 miles, Liver...   \n",
      "\n",
      "                                      Agency Details  \n",
      "0  Felicity J Lord, Stoke Newington\\n69 Stoke New...  \n",
      "1  Douglas and Gordon, London\\n41 Paradise Walk, ...  \n",
      "2  Luxury Living Homes International, London\\n71-...  \n",
      "3  Chestertons New Homes, Chestertons New Homes\\n...  \n",
      "4  Global 1, London\\n23 Berkeley Square, Mayfair,...  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "from lxml import html\n",
    "\n",
    "# Initialize lists to store the data\n",
    "all_apartment_links = []\n",
    "all_address = []\n",
    "all_price = []\n",
    "all_property_types = []\n",
    "all_added_date = []\n",
    "all_bedrooms = []\n",
    "all_bathrooms = []\n",
    "all_size = []\n",
    "all_leasehold_freehold = []\n",
    "all_council_tax = []\n",
    "all_parking = []\n",
    "all_garden = []\n",
    "all_stations = []\n",
    "all_agency_details = []\n",
    "\n",
    "# Define the list of borough codes (hackney, tower hamlet)\n",
    "boroughs = [\"REGION%5E93953\", \"REGION%5E61417\"]\n",
    "\n",
    "# Set up the Chrome WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Loop through each borough\n",
    "for borough in boroughs:\n",
    "    # Initialize the starting index for each borough\n",
    "    index = 0\n",
    "\n",
    "    # Get the total number of listings for the current borough\n",
    "    rightmove_initial = f\"https://www.rightmove.co.uk/property-for-sale/find.html?searchType=SALE&locationIdentifier={borough}&insId=1&radius=0.0&minPrice=&maxPrice=&minBedrooms=&maxBedrooms=&displayPropertyType=&maxDaysSinceAdded=&_includeSSTC=on&sortByPriceDescending=&primaryDisplayPropertyType=&secondaryDisplayPropertyType=&oldDisplayPropertyType=&oldPrimaryDisplayPropertyType=&newHome=&auction=false\"\n",
    "    driver.get(rightmove_initial)\n",
    "    time.sleep(3)  # Allow time for the page to load\n",
    "    number_of_listings = driver.find_element(By.CLASS_NAME, \"searchHeader-resultCount\").text\n",
    "    number_of_listings = int(number_of_listings.replace(\",\", \"\"))\n",
    "\n",
    "    # Loop through pages for the current borough\n",
    "    while index < number_of_listings:\n",
    "        try:\n",
    "            # Construct the URL for the current page\n",
    "            rightmove = f\"https://www.rightmove.co.uk/property-for-sale/find.html?searchType=SALE&locationIdentifier={borough}&insId=1&index={index}&radius=0.0&minPrice=&maxPrice=&minBedrooms=&maxBedrooms=&displayPropertyType=&maxDaysSinceAdded=&_includeSSTC=on&sortByPriceDescending=&primaryDisplayPropertyType=&secondaryDisplayPropertyType=&oldDisplayPropertyType=&oldPrimaryDisplayPropertyType=&newHome=&auction=false\"\n",
    "            driver.get(rightmove)\n",
    "            time.sleep(3)  # Allow time for the page to load\n",
    "\n",
    "            # Get the list of apartments\n",
    "            apartments = driver.find_elements(By.CLASS_NAME, \"l-searchResult\")\n",
    "\n",
    "            # Check if there are no more apartments found\n",
    "            if not apartments:\n",
    "                print(f\"No more apartments found in borough {borough}.\")\n",
    "                break\n",
    "\n",
    "            # Clear the lists for the current page to avoid duplicates\n",
    "            page_apartment_links = []\n",
    "            page_address = []\n",
    "            page_price = []\n",
    "            page_added_date = []\n",
    "\n",
    "            for apartment in apartments:\n",
    "                # Append link\n",
    "                try:\n",
    "                    link = apartment.find_element(By.CLASS_NAME, \"propertyCard-link\").get_attribute(\"href\")\n",
    "                    page_apartment_links.append(link)\n",
    "                except:\n",
    "                    page_apartment_links.append(\"N/A\")\n",
    "\n",
    "                # Append address\n",
    "                try:\n",
    "                    address = apartment.find_element(By.CLASS_NAME, \"propertyCard-address\").text.strip()\n",
    "                    page_address.append(address)\n",
    "                except:\n",
    "                    page_address.append(\"N/A\")\n",
    "\n",
    "                # Append price\n",
    "                try:\n",
    "                    price = apartment.find_element(By.CLASS_NAME, \"propertyCard-priceValue\").text.strip()\n",
    "                    page_price.append(price)\n",
    "                except:\n",
    "                    page_price.append(\"N/A\")\n",
    "\n",
    "                # Append details\n",
    "                try:\n",
    "                    details = apartment.find_element(By.CLASS_NAME, \"propertyCard-branchSummary-addedOrReduced\").text.strip()\n",
    "                    page_added_date.append(details)\n",
    "                except:\n",
    "                    page_added_date.append(\"N/A\")\n",
    "\n",
    "            # Visit each property link to extract more details\n",
    "            for link in page_apartment_links:\n",
    "                if link == \"N/A\":\n",
    "                    all_property_types.append(\"N/A\")\n",
    "                    all_bedrooms.append(\"N/A\")\n",
    "                    all_bathrooms.append(\"N/A\")\n",
    "                    all_size.append(\"N/A\")\n",
    "                    all_leasehold_freehold.append(\"N/A\")\n",
    "                    all_council_tax.append(\"N/A\")\n",
    "                    all_parking.append(\"N/A\")\n",
    "                    all_garden.append(\"N/A\")\n",
    "                    all_stations.append(\"N/A\")\n",
    "                    all_agency_details.append(\"N/A\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    driver.get(link)\n",
    "                    time.sleep(3)  # Allow time for the page to load\n",
    "\n",
    "                    # Get the page source and parse it with lxml\n",
    "                    page_source = driver.page_source\n",
    "                    tree = html.fromstring(page_source)\n",
    "\n",
    "                    try:\n",
    "                        property_type = tree.xpath('//*[@id=\"info-reel\"]/div[1]/dd/span/p/text()')[0]\n",
    "                    except:\n",
    "                        property_type = \"N/A\"\n",
    "                    all_property_types.append(property_type)\n",
    "\n",
    "                    try:\n",
    "                        bedrooms = tree.xpath('//*[@id=\"info-reel\"]/div[2]/dd/span/p/text()')[0]\n",
    "                    except:\n",
    "                        bedrooms = \"N/A\"\n",
    "                    all_bedrooms.append(bedrooms)\n",
    "\n",
    "                    try:\n",
    "                        bathrooms = tree.xpath('//*[@id=\"info-reel\"]/div[3]/dd/span/p/text()')[0]\n",
    "                    except:\n",
    "                        bathrooms = \"N/A\"\n",
    "                    all_bathrooms.append(bathrooms)\n",
    "\n",
    "                    try:\n",
    "                        size1 = tree.xpath('//*[@id=\"info-reel\"]/div[4]/dd/span/p[1]/text()')\n",
    "                        size2 = tree.xpath('//*[@id=\"info-reel\"]/div[4]/dd/span/p[2]/text()')\n",
    "                        size = \", \".join(filter(None, [size1[0] if size1 else None, size2[0] if size2 else None]))\n",
    "                        if not size:\n",
    "                            size = \"N/A\"\n",
    "                    except:\n",
    "                        size = \"N/A\"\n",
    "                    all_size.append(size)\n",
    "\n",
    "                    # Use driver.find_element for leasehold_freehold\n",
    "                    try:\n",
    "                        leasehold_freehold = driver.find_element(By.XPATH, '//*[@id=\"info-reel\"]/div[5]').text\n",
    "                    except:\n",
    "                        leasehold_freehold = \"N/A\"\n",
    "                    all_leasehold_freehold.append(leasehold_freehold)\n",
    "\n",
    "                    try:\n",
    "                        council_tax = tree.xpath(\"//dd[@class='_2zXKe70Gdypr_v9MUDoVCm']/text()\")[0]\n",
    "                    except:\n",
    "                        council_tax = \"N/A\"\n",
    "                    all_council_tax.append(council_tax)\n",
    "\n",
    "                    try:\n",
    "                        parking = tree.xpath(\"(//span[@class='_3rQAUgsu_ICdA55QUiiUxg'])[1]/text()\")[0]\n",
    "                    except:\n",
    "                        parking = \"N/A\"\n",
    "                    all_parking.append(parking)\n",
    "\n",
    "                    try:\n",
    "                        garden = tree.xpath(\"(//span[@class='_3rQAUgsu_ICdA55QUiiUxg'])[2]/text()\")[0]\n",
    "                    except:\n",
    "                        garden = \"N/A\"\n",
    "                    all_garden.append(garden)\n",
    "\n",
    "                    try:\n",
    "                        station_elements = tree.xpath(\"//div[@class='mlEuHXZpfrrzJtwlRmwBe']\")\n",
    "                        stations = \", \".join([station.text_content() for station in station_elements])\n",
    "                    except:\n",
    "                        stations = \"N/A\"\n",
    "                    all_stations.append(stations)\n",
    "\n",
    "                    # Append agency details using driver.find_element\n",
    "                    try:\n",
    "                        agency_details = driver.find_element(By.XPATH, '//*[@id=\"root\"]/main/div/div[2]/div/article[4]/div[1]').text\n",
    "                    except:\n",
    "                        agency_details = \"N/A\"\n",
    "                    all_agency_details.append(agency_details)\n",
    "\n",
    "                except Exception as err:\n",
    "                    print(f\"Error occurred while fetching details for link {link}: {err}\")\n",
    "                    all_property_types.append(\"N/A\")\n",
    "                    all_bedrooms.append(\"N/A\")\n",
    "                    all_bathrooms.append(\"N/A\")\n",
    "                    all_size.append(\"N/A\")\n",
    "                    all_leasehold_freehold.append(\"N/A\")\n",
    "                    all_council_tax.append(\"N/A\")\n",
    "                    all_parking.append(\"N/A\")\n",
    "                    all_garden.append(\"N/A\")\n",
    "                    all_stations.append(\"N/A\")\n",
    "                    all_agency_details.append(\"N/A\")\n",
    "\n",
    "            # Add current page data to the main lists\n",
    "            all_apartment_links.extend(page_apartment_links)\n",
    "            all_address.extend(page_address)\n",
    "            all_price.extend(page_price)\n",
    "            all_added_date.extend(page_added_date)\n",
    "\n",
    "            # Increment the index for pagination\n",
    "            index += 24  # Assuming each page shows 24 listings\n",
    "\n",
    "            # Add a delay to avoid being blocked by the website\n",
    "            time.sleep(2)\n",
    "\n",
    "        except Exception as err:\n",
    "            print(f\"Error occurred: {err}\")\n",
    "            break\n",
    "\n",
    "# Ensure all lists have the same length\n",
    "min_length = min(len(all_apartment_links), len(all_address), len(all_price), len(all_property_types), len(all_added_date), len(all_bedrooms), len(all_bathrooms), len(all_size), len(all_leasehold_freehold), len(all_council_tax), len(all_parking), len(all_garden), len(all_stations), len(all_agency_details))\n",
    "all_apartment_links = all_apartment_links[:min_length]\n",
    "all_address = all_address[:min_length]\n",
    "all_price = all_price[:min_length]\n",
    "all_property_types = all_property_types[:min_length]\n",
    "all_added_date = all_added_date[:min_length]\n",
    "all_bedrooms = all_bedrooms[:min_length]\n",
    "all_bathrooms = all_bathrooms[:min_length]\n",
    "all_size = all_size[:min_length]\n",
    "all_leasehold_freehold = all_leasehold_freehold[:min_length]\n",
    "all_council_tax = all_council_tax[:min_length]\n",
    "all_parking = all_parking[:min_length]\n",
    "all_garden = all_garden[:min_length]\n",
    "all_stations = all_stations[:min_length]\n",
    "all_agency_details = all_agency_details[:min_length]\n",
    "\n",
    "# Convert data to DataFrame\n",
    "data = {\n",
    "    \"Links\": all_apartment_links,\n",
    "    \"Address\": all_address,\n",
    "    \"Price\": all_price,\n",
    "    \"Property Type\": all_property_types,\n",
    "    \"Added Date\": all_added_date,\n",
    "    \"Bedrooms\": all_bedrooms,\n",
    "    \"Bathrooms\": all_bathrooms,\n",
    "    \"Size\": all_size,\n",
    "    \"Leasehold/Freehold\": all_leasehold_freehold,\n",
    "    \"Council Tax\": all_council_tax,\n",
    "    \"Parking\": all_parking,\n",
    "    \"Garden\": all_garden,\n",
    "    \"Stations\": all_stations,\n",
    "    \"Agency Details\": all_agency_details\n",
    "}\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "df.to_csv(\"all_listings.csv\", encoding=\"utf-8\", header=True, index=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"Total listings scraped:\", len(all_apartment_links))\n",
    "print(\"Sample data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a5547ceb-ff55-4e78-91d3-814bdd62e4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File converted and saved as all_listings.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "csv_file = \"all_listings.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Save as an Excel file\n",
    "excel_file = \"all_listings.xlsx\"\n",
    "df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f\"File converted and saved as {excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "73040f25-2dde-4d58-a499-d098e5a15918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cleaned and saved as all_listings_cleaned.csv\n",
      "File converted and saved as all_listings_cleaned.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Clean the Price column\n",
    "# Get the date of yesterday\n",
    "# Clean the Added Date column\n",
    "# Define the cleaning function\n",
    "# Convert Size values to numeric (removing 'sq m' and handling commas)\n",
    "# Clean the Bedrooms column to ensure it only contains numeric values and convert to integer\n",
    "# Calculate the overall average size for one-bedroom properties\n",
    "# Fill empty size cells with the average size multiplied by the number of bedrooms\n",
    "# Convert the size back to the original format with one decimal place\n",
    "# Clean the Leasehold/Freehold column\n",
    "# Clean the Stations column to keep only the shortest distance\n",
    "# Clean the Agency Details column to keep only the name of the agency\n",
    "# Clean the Council Tax column\n",
    "# Define the replacements for the Parking column\n",
    "# Replace the values in the Parking column\n",
    "# Clean the Garden column\n",
    "# Remove rows where the Bathrooms column contains text\n",
    "# Remove rows with empty cells in the 'Property Type' column and those with 'Plot' as the 'Property Type'\n",
    "# Rename the column \n",
    "# Replace any remaining nan values with 0\n",
    "# Create Unique_ID column by combining Price, Property Type, Address, Bedrooms, and Bathrooms\n",
    "# Remove duplicate rows based on the Unique_ID column\n",
    "# Extract postcode from Address column\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV file\n",
    "csv_file = \"all_listings.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Clean the Price column\n",
    "df['Price'] = df['Price'].str.replace('£', '').str.replace(',', '').astype(int)\n",
    "\n",
    "# Get the date of yesterday\n",
    "yesterday = (datetime.now() - timedelta(1)).strftime(\"%d/%m/%Y\")\n",
    "\n",
    "# Clean the Added Date column\n",
    "def process_date(date_str):\n",
    "    if isinstance(date_str, float) and pd.isna(date_str):\n",
    "        return \"\"\n",
    "    date_str = str(date_str)\n",
    "    if \"Added on\" in date_str:\n",
    "        return date_str.replace(\"Added on \", \"\")\n",
    "    elif \"Reduced yesterday\" in date_str or \"Added yesterday\" in date_str:\n",
    "        return yesterday\n",
    "    elif \"Reduced on\" in date_str:\n",
    "        return date_str.replace(\"Reduced on \", \"\")\n",
    "    else:\n",
    "        return date_str\n",
    "\n",
    "df['Added Date'] = df['Added Date'].apply(process_date)\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_size(size_str):\n",
    "    return ', '.join([s for s in str(size_str).split(', ') if 'sq m' in s])\n",
    "\n",
    "# Apply the cleaning function\n",
    "df['Size'] = df['Size'].apply(clean_size)\n",
    "\n",
    "# Convert Size values to numeric (removing 'sq m' and handling commas)\n",
    "def parse_size(size_str):\n",
    "    try:\n",
    "        return float(size_str.replace('sq m', '').replace(',', '').strip())\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['Size'] = df['Size'].apply(parse_size)\n",
    "\n",
    "# Clean the Bedrooms column to ensure it only contains numeric values and convert to integer\n",
    "def clean_bedrooms(bedroom_str):\n",
    "    try:\n",
    "        return int(float(bedroom_str))\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "df['Bedrooms'] = df['Bedrooms'].apply(clean_bedrooms)\n",
    "\n",
    "# Calculate the overall average size for one-bedroom properties\n",
    "average_size_one_bedroom = df['Size'].mean() / df['Bedrooms'].mean()\n",
    "\n",
    "# Fill empty size cells with the average size multiplied by the number of bedrooms\n",
    "def fill_empty_size(row):\n",
    "    if pd.isna(row['Size']) or row['Size'] == '':\n",
    "        try:\n",
    "            return average_size_one_bedroom * int(row['Bedrooms'])\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    return row['Size']\n",
    "\n",
    "df['Size'] = df.apply(fill_empty_size, axis=1)\n",
    "\n",
    "# Convert the size back to the original format with one decimal place\n",
    "df['Size'] = df['Size'].apply(lambda x: f\"{x:.1f}\" if not pd.isna(x) else '')\n",
    "\n",
    "# Clean the Leasehold/Freehold column\n",
    "def clean_leasehold_freehold(value):\n",
    "    if pd.isna(value) or \"Ask agent\" in value:\n",
    "        return \"0\"\n",
    "    return re.sub(r'TENURE\\s*', '', value).strip()\n",
    "\n",
    "df['Leasehold/Freehold'] = df['Leasehold/Freehold'].astype(str).apply(clean_leasehold_freehold)\n",
    "\n",
    "# Clean the Stations column to keep only the shortest distance\n",
    "def get_shortest_station(stations_str):\n",
    "    distances = re.findall(r'(\\d+\\.\\d+)', stations_str)\n",
    "    shortest_distance = min(distances, key=float) if distances else \"0\"\n",
    "    return shortest_distance\n",
    "\n",
    "df['Stations'] = df['Stations'].apply(get_shortest_station)\n",
    "\n",
    "# Clean the Agency Details column to keep only the name of the agency\n",
    "df['Agency Details'] = df['Agency Details'].apply(lambda x: str(x).split(',')[0])\n",
    "\n",
    "# Clean the Council Tax column\n",
    "def clean_council_tax(tax_str):\n",
    "    if isinstance(tax_str, float) and pd.isna(tax_str):\n",
    "        return \"0\"\n",
    "    tax_str = str(tax_str)\n",
    "    if \"Ask agent\" in tax_str or \"Ask developer\" in tax_str:\n",
    "        return \"0\"\n",
    "    tax_str = tax_str.replace(\"Band: \", \"\")\n",
    "    if tax_str == \"TBC\":\n",
    "        return \"0\"\n",
    "    return tax_str\n",
    "\n",
    "df['Council Tax'] = df['Council Tax'].apply(clean_council_tax)\n",
    "\n",
    "# Define the replacements for the Parking column\n",
    "parking_replacements = {\n",
    "    'Ask agent': 'FALSE',\n",
    "    'Private': 'TRUE',\n",
    "    'Allocated': 'TRUE',\n",
    "    'Off street': 'TRUE',\n",
    "    'On street': 'TRUE',\n",
    "    'Garage': 'TRUE',\n",
    "    'Underground': 'TRUE',\n",
    "    'Permit': 'TRUE',\n",
    "    'Ask developer': 'FALSE',\n",
    "    'Residents': 'TRUE',\n",
    "    'Disabled parking': 'TRUE',\n",
    "    'No parking': 'FALSE',\n",
    "    'Gated': 'TRUE',\n",
    "    'Yes' : 'TRUE',\n",
    "    pd.NA: 'FALSE',\n",
    "    'nan': 'FALSE'  \n",
    "}\n",
    "\n",
    "# Replace the values in the Parking column\n",
    "df['Parking'] = df['Parking'].replace(parking_replacements)\n",
    "\n",
    "# Clean the Garden column\n",
    "def clean_garden(garden_str):\n",
    "    if isinstance(garden_str, float) and pd.isna(garden_str):\n",
    "        return 'FALSE'\n",
    "    garden_str = str(garden_str)\n",
    "    if \"Ask agent\" in garden_str or \"Ask developer\" in garden_str:\n",
    "        return 'FALSE'\n",
    "    return 'TRUE'\n",
    "\n",
    "df['Garden'] = df['Garden'].apply(clean_garden)\n",
    "\n",
    "# Remove rows where the Bathrooms column contains text\n",
    "def is_valid_bathroom(bathroom_str):\n",
    "    try:\n",
    "        int(bathroom_str)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "df = df[df['Bathrooms'].apply(is_valid_bathroom)]\n",
    "\n",
    "# Remove rows with empty cells in the 'Property Type' column and those with 'Plot' as the 'Property Type'\n",
    "df = df[df['Property Type'].notna() & (df['Property Type'] != '') & (df['Property Type'].str.lower() != 'plot')]\n",
    "\n",
    "# Rename the column \n",
    "df.rename(columns={'Size': 'Size (sq m)'}, inplace=True)\n",
    "df.rename(columns={'Stations': 'Stations (miles)'}, inplace=True)\n",
    "df.rename(columns={'Price': 'Price (£)'}, inplace=True)\n",
    "df.rename(columns={'Leasehold/Freehold': 'TENURE'}, inplace=True)\n",
    "\n",
    "# Replace any remaining nan values with 0\n",
    "df = df.replace({np.nan: '0', '': '0'})\n",
    "\n",
    "# Create Unique_ID column by combining Price, Property Type, Address, Bedrooms, and Bathrooms\n",
    "df['Unique_ID'] = df.apply(lambda row: f\"{row['Price (£)']}_{row['Property Type']}_{row['Address']}_{row['Bedrooms']}_{row['Bathrooms']}\", axis=1)\n",
    "\n",
    "# Remove duplicate rows based on the Unique_ID column\n",
    "df = df.drop_duplicates(subset=['Unique_ID'])\n",
    "\n",
    "# Extract postcode from Address column\n",
    "def extract_postcode(address):\n",
    "    parts = address.split(',')\n",
    "    last_part = parts[-1].strip()\n",
    "    \n",
    "    # Check if the last part has a number\n",
    "    if any(char.isdigit() for char in last_part):\n",
    "        # If it's a full postcode (contains a space), return the first part only\n",
    "        if ' ' in last_part:\n",
    "            first_part = last_part.split(' ')[0]\n",
    "            # Check if the first part contains a number\n",
    "            if any(char.isdigit() for char in first_part):\n",
    "                return first_part\n",
    "        else:\n",
    "            # Return the last part as it is if it contains a number\n",
    "            return last_part\n",
    "    return '0'  # Return '0' if no postcode is found\n",
    "\n",
    "df['Address'] = df['Address'].apply(extract_postcode)\n",
    "\n",
    "# Convert the Bedrooms column to integer type\n",
    "df['Bedrooms'] = df['Bedrooms'].astype(int)\n",
    "\n",
    "# Drop the 'Links' column\n",
    "df = df.drop(columns=['Links'])\n",
    "\n",
    "# Save the cleaned data to a CSV file\n",
    "cleaned_csv_file = \"all_listings_cleaned.csv\"\n",
    "df.to_csv(cleaned_csv_file, index=False)\n",
    "\n",
    "print(f\"File cleaned and saved as {cleaned_csv_file}\")\n",
    "\n",
    "\n",
    "# Save as an Excel file\n",
    "excel_file = \"all_listings_cleaned.xlsx\"\n",
    "df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f\"File converted and saved as {excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d872e-ee0d-47d6-a86b-6872750f9c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
